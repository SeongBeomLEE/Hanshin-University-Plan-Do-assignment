{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvDjsFzYmPVSVO71XEERee"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfAz2KFgh3lY"
      },
      "source": [
        "# 한신대학교 e-비즈니스학과 201646006 이성범 PD학기제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR6g-xqIYO-M"
      },
      "source": [
        "# 군집화를 왜 하는 것인가?\n",
        "\n",
        "오늘날 대부분의 머신러닝 알고리즘은 지도 학습 기반이다. 하지만 사용할 수 있는 데이터는 대부분 레이블이 존재하지 않는다. 레이블이 존재하지 않는다면 지도 학습 기반의 알고리즘을 사용할 수 없다. 그렇다면 레이블이 존재하지 않을 때 우리는 어떠한 방식으로 문제를 해결할 수 있을까? 바로 레이블이 없는 데이터를 분류하는 알고리즘인 비지도학습으로 해결할 수 있다. 가령 우리가 고객을 분류하는 알고리즘을 만들고 싶다고 가정할 때 우리는 가장 먼저 지도학습인 분류 알고리즘을 생각할 것이다. 하지만 현실의 데이터에는 고객이 분류되어 있는 레이블이 존재하지 않는다. 이러한 문제에 직면했을 때 우리는 해결책으로 군집화를 제시할 수 있다. 군집화 알고리즘을 통해서 데이터내의 패턴을 찾고 그 패턴을 기반으로 라벨링을 하고 라벨링된 데이터를 기반으로 지도학습에 활용하는 등 다양한 방식으로 활용할 수 있다.\n",
        "\n",
        "이렇듯 군집화는 비슷한 샘플을 구별해 하나의 클러스터 또는 비슷한 샘플의 그룹으로 할당하는 알고리즘을 칭한다. 군집화는 \n",
        "\n",
        "- 고객 분류 : 고객의 구매이력, 웹사이트의 행동을 기반으로 클러스터를 생성할 수 있다.\n",
        "- 데이터 분석 : 클러스터를 나눠 따로 분석하면 데이터의 특성을 더 쉽게 발견할 수 있다.\n",
        "- 차원 축소 기법 : 군집화를 통해서 샘플의 친화성을 더 높일 수 있다.\n",
        "- 이상치 탐지 : 모든 클라스터에 친화성이 낮은 샘플은 이상치일 가능성이 높다.\n",
        "- 준지도 학습 : 레이블된 샘플이 적다면 군집을 수행하고 동일한 클러스터에 있는 모든 샘플에 레이블을 전파하여 지도 학습에 필요한 레이블의 수를 늘릴 수 있다.\n",
        "- 검색 엔진 : 비슷한 특징들끼리 서로 묶어서 추천 단어를 제시해줄 수 있다.\n",
        "- 이미지 분할 : 색을 기반으로 클러스터를 나눌 수 있다.\n",
        "\n",
        "등 다양한 애플리케이션에서 사용된다.\n",
        "\n",
        "컴퓨터 과학자 얀 르쿤은 지능이 케이크라면 비지도 학습은 케이크의 빵이고, 지도 학습은 케이크 위의 크림이고, 강화 학습은 케이크 위의 체리라고 했다. 이렇듯 비지도 학습은 큰 잠재력을 가진 알고리즘이며 그 중 군집화는 비지도학습의 큰 축을 담당하고 있을 정도로 중요한 알고리즘이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0PUYZ-aYzyB"
      },
      "source": [
        "# 군집화 방법\n",
        "\n",
        "Clustering은 소속 집단의 정보가 없고, 모르는 상태에서 비슷한 집단으로 묶는 방법이다. 즉 label 없는 data를 나누는 방법이다. 데이터 간의 유사성을 찾아 그를 기준으로 그룹을 찾고 구해진 그룹들을 직접 사용하거나 에측을 위한 회귀나 분류 모델의 feature 또는 label로 활용할 수 있다.\n",
        "\n",
        "최적의 군집은 군집내 데이터 간의 거리는 매우 가깝고(군집 내 응집도 최대화) 군집간에 거리는 매우 먼 것이(군집 간 분리도 최대화) 최적의 군집이라고 할 수 있다.\n",
        "\n",
        "군집화는 크게\n",
        "\n",
        "- 비계층적 군집화(Partitioning Clustering)\n",
        " - 중심 기반 군집화(Ceter-based Clustering)\n",
        "   - K-Means 알고리즘\n",
        " - 밀도 기반 군집화(Density-based Clustering)\n",
        "   - DBSCAN(Density Based Spatial Clustering of Applications with Noise)\n",
        "   - GMM(Gaussian Mixture Model)\n",
        "- 계층적 군집화(Hierarchical Clustering)\n",
        " - 병합형 계층적 군집화(Agglomerative Hierarchical Clustering)\n",
        " - 분리형 계층적 군집화(Divisive Hierarchical Clustering)\n",
        "\n",
        "으로 나뉘어진다.\n",
        "\n",
        "## K - Means\n",
        "\n",
        "우선 중심 기반 군집화의 대표적인 알고리즘인 K - Means 알고리즘에 대하여 알아보겠다.\n",
        "\n",
        "k-means 클러스터링은 대표적인 클러스터링 알고리즘 중 하나로, 각 클러스터에 할당된 데이터 포인트들의 평균 좌표를 이용해 중심점을 반복적으로 업데이트하며 클러스터를 형성하는 알고리즘 이다.\n",
        "\n",
        "k-means Clustering 알고리즘은 3가지 단계로 이루어진다.\n",
        "- Step 1. 각 데이터 포인트 i 에 대해 가장 가까운 중심점을 찾고, 그 중심점에 해당하는 클러스터를 할당한다.\n",
        "가까운 중심점을 찾을 때는, Euclidean Distance(점과 점사이의 가장 짧은 거리르 계산하는 거리 측정 방식) 또는 Manhattan Distance(각 축에 대해 수직으로만 이동하여 계산하는 거리 측정방식)를 사용한다,\n",
        "- Step 2. 할당된 클러스터를 기반으로 새로운 중심점을 계산합니다. 중심점은 클러스터 내부 점들 좌표의 산술 평균(mean) 으로 구한다.\n",
        "- Step 3. 각 클러스터의 할당이 바뀌지 않을 때까지 반복한다.\n",
        "\n",
        "## DBSCAN\n",
        "\n",
        "밀도 기반 군집화의 대표적인 알고리즘이다. DBSCAN은 특정 공간 내에 데이터 밀도 차이를 기반 알고리즘으로 하고 있어서 복잡한 기하학적 분포도를 가진 데이터 세트에 대해서도 군집화를 잘 수행한다.\n",
        "\n",
        "주요 파라미터\n",
        "- 입실론 주변 영역(epsilon) : 개별 데이터를 중심으로 입실론 반경을 가지는 원형의 영역\n",
        "- 최소 데이터의 개수(min points) : 개별 데이터의 입실론 주변 영역에 포함되는 타 데이터의 개수\n",
        "\n",
        "하이퍼 파라미터\n",
        "- eps : 입실론 주변 영역의 반경을 의미\n",
        "- min_samples : 핵심 포인트가 되기 위해 입실론 주변 영역 내에 포함돼야 할 데이터의 최소 개수를 의미(min points + 1)\n",
        "\n",
        "핵심 포인트 : 주변 영역 내에 최소 데이터 개수 이상의 타 데이터를 가지고 있을 경우 해당 데이터를 핵심 포인트라고 한다.\n",
        "\n",
        "특정 핵심 포인트에서 직접 접근이 가능한 다른 핵심 포인트를 서로 연결하면서 군집화를 구성하며 이러한 방식으로 점차적으로 군집 영역을 확장해 나가는 것이 바로 DBSCAN 이다.\n",
        "\n",
        "## GMM\n",
        "\n",
        "GMM 군집화는 군집화를 적용하고자 하는 데이터가 여러 개의 가우시안 분포를 가진 데이터 집합들이 섞여서 생성된 것이라는 가정하에 군집화를 수행하는 방식이다.\n",
        "\n",
        "정규 분포로도 알려진 가우시안 분포는 좌우 대칭형의 종 형태를 가진 분포로 평균을 중심으로 높은 데이터 분포도를 가지고 있는 것이 특징이다.\n",
        "\n",
        "GMM은 데이터를 여러 개의 가우시안 분포가 섞인 것으로 간주하며 섞인 데이터 분포에서 개별 유형의 가우시안 분포를 추출합니다.\n",
        "\n",
        "전체 데이터 세트는 서로 다른 정규 분포 형태를 가진 여러 가지 확률 분포 곡선으로 구성될 수 있으며, 이러한 서로 다른 정규 분포에 기반해 군집화를 수행하는데 예를 들어 1000개의 데이터 세트가 있다면 이를 구성하는 여러 개의 정규 분포 곡선을 추출하고, 개별 데이터가 이 중 어떤 정규 분포에 속하는지 결정하는 방식이다.\n",
        "\n",
        "이와 같은 방식을 GMM에서는 모수추정이라고 하며, 대표저그로 모수 추정은 2가지를 추정한다.\n",
        "1. 개별 정규분포의 평균과 분산\n",
        "2. 각 데이터가 어떤 정규 분포에 해당되는지의 확률\n",
        "\n",
        "## 계층적 군집화\n",
        "\n",
        "계층적 군집화는 거리(Distance) 또는 유사도(Similarity)를 기반으로 클러스터를 형성하는 알고리즘 이다.\n",
        "k-means Clustering과 다르게 클러스터의 수를 설정해 줄 필요가 없으며, 클러스터 형태를 시각적으로 표현해주는 덴드로그램을 통해 적절한 클러스터의 수를 선택할 수 있다.\n",
        "\n",
        "계층적 군집화는 Bottom-Up 방식의 병합형 계층적 군집화와 Top-Down 방식의 분리형 계층적 군집화로 나뉘어진다.\n",
        "\n",
        "Agglomerative Method를 사용한 Hierarchical Clustering 알고리즘은 3가지 단계로 이루어진다.\n",
        "- Step 1. 각 데이터 포인트를 클러스터로 할당한다. (n개의 클러스터)\n",
        "- Step 2. 가까운 클러스터끼리 병합한다.\n",
        "- Step 3. 1개의 클러스터가 될 때까지 반복한다.\n",
        "\n",
        "위의 방식을 반대로 진행한다면 바로 Divisive Method 이다.\n",
        "\n",
        "계층적 군집화에서 가장 가까운 클러스터를 찾기 위해 거리를 계산하는 방식이 K-Means와 조금 다르다. K-means의 경우 클러스의 중심점 간의 거리로 클러스터간 거리를 계산했지만 계층적 군집화의 경우 클러스터간 거리를 계산하는 방식이 크게\n",
        "\n",
        "- Single Linkage : 두 클러스터 내의 가장 가까운 점 사이의 거리를 기준으로\n",
        "\n",
        "- Complete Linkage : 두 클러스터 내의 가장 먼 점 사이의 거리를 기준으로\n",
        "\n",
        "- Average Linkage : 두 클러스터 내의 모든 점 사이의 평균 거리를 기준으로\n",
        "\n",
        "등 으로 나뉘어진다.\n",
        "\n",
        "## 군집 평가\n",
        "\n",
        "군집을 제대로 설정했느냐의 평가는 Silhouette Score를 통해서 평가할 수 있다.\n",
        "\n",
        "- 실루엣 값은 한 클러스터 안의 데이터들이 다른 클러스터와 비교해서 얼마나 비슷한가를 나타낸다.\n",
        "- 같은 클러스터 내의 점들간 거리는 가깝고(cohesion) 서로 다른 클러스터 간의 거리는 멀수록(separation) 높은 값을 얻을 수 있다.\n",
        "- 실루엣 값이 1에 근접한다는 것은 같은 클러스터 내의 평균거리가 다른 클러스터와의 평균거리보다 가깝다는 것을 의미한다.\n",
        "- 일반적으로 실루엣 값이 0.5보다 크다면 데이터가 잘 클러스터링 되었다는 것을 의미한다.\n",
        "\n",
        "따라서 같은 클러스터는 가깝고 다른 클러스터들 끼리는 먼형태 일수록 1에 가까운 실루엣 값을 얻을 수 있다.\n",
        "\n",
        "이밖에도 모든 샘플의 실루엣 계수를 할당된 클러스터와 계숫값으로 정렬하여 그리는 실루엣 다이어그램을 통해서도 적절한 군집의 수가 군집이 제대로 되었는지 평가할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkw8zV_bY1fx"
      },
      "source": [
        "# 군집화 실습\n",
        "\n",
        "군집화 실습은 캐글의 대표적인 군집화 튜토리얼 데이터인 Mall Customer Segmentation Data를 가지고 진행하겠다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc9h3r-x-c4f"
      },
      "source": [
        "# 참고자료\n",
        "\n",
        "- 파이썬 머신러닝 완벽 가이드, 권철민\n",
        "- 파이썬 딥러닝 파이토치, 이경택\n",
        "- 핸즈온 머신러닝, 박해선\n",
        "- 데이터 사이언스 스쿨, https://datascienceschool.net/\n",
        "- 데이터 분석 대표 대학생 연합 동아리 Tobigs, http://www.datamarket.kr/\n",
        "- DeepLearnig.AI Course 1 ~ 5, Andrew Ng, https://www.youtube.com/c/Deeplearningai/playlists\n",
        "- 모두를 위한 딥러닝 시즌 2, https://deeplearningzerotoall.github.io/season2/\n",
        "- T아카데미 Scikit-Learn으로 다지는 머신러닝 기초, 강천성, https://tacademy.skplanet.com/live/player/onlineLectureDetail.action"
      ]
    }
  ]
}